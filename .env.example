# Copy to .env and fill values

# --- Provider selection (default: openai) ---
# Embeddings: openai | huggingface (local) | ollama (local)
# LLM: openai | ollama (local)
# EMBEDDING_PROVIDER=openai
# LLM_PROVIDER=openai

# Required for OpenAI
OPENAI_API_KEY=

# If using Chroma persistent directory
CHROMA_PERSIST_DIR=./.chromadb

# --- HuggingFace (EMBEDDING_PROVIDER=huggingface) ---
# Optional: default is sentence-transformers/all-MiniLM-L6-v2
# HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

#EMBEDDING_PROVIDER=huggingface
EMBEDDING_PROVIDER=ollama

# --- Ollama (EMBEDDING_PROVIDER=ollama or LLM_PROVIDER=ollama) ---
# Install Ollama from https://ollama.com, then pull a model, e.g.: ollama pull tinyllama
#
# Small LLM options (set OLLAMA_LLM_MODEL=...):
#   llama3.2:1b   ~1.3 GB  (1B, very small, Meta)
#   tinyllama     ~640 MB  (smallest, good for testing)
#   phi2          ~1.6 GB  (2.7B, good reasoning)
#   gemma2:2b     ~1.6 GB  (2B, instruction-following)
#   llama2        ~3.8 GB  (7B, better quality)
#
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_LLM_MODEL=tinyllama

LLM_PROVIDER=ollama
OLLAMA_LLM_MODEL=llama3.2:1b

# Optional: set OpenAI API base if using a proxy or different endpoint
# OPENAI_API_BASE=
